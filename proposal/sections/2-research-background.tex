\section{Research Background}
This section will provide justifications for the project and necessary knowledge for the reader in order to understand technical terms used throughout the report.
\subsection{Justification of the Project}

The project focuses on developing emotional wellbeing robots that promote mental wellness and positivity for users under the influence of stress and anxiety. In general, emotion-related robots are designed to respond to human emotions and can potentially achieve clinical outcomes similar to traditional therapy \cite{palmer2024}. Research has shown that digital interventions, such as AI-powered mental wellbeing robots, can effectively reduce anxiety symptoms and address unmet mental health needs, offering a promising solution to supplement traditional therapeutic approaches \cite{mamatha2024}.

The mental health industry faces significant challenges that cannot be fully addressed through human intervention alone \cite{charles2024}. Key issues include loneliness and social isolation, which are major contributors to depression, anxiety, and overall deterioration in mental health \cite{goh2023}, as well as therapeutic challenges where patients with dementia or other cognitive impairments often struggle with traditional therapeutic activities \cite{sukhawathanakul2021}.

In a study by the National Innovation Agency (NIA) based in Thailand, it was identified that the concept of "Terror Outburst" would become a pressing issue in Thailand by the year 2033 \cite{nia2023}. To elaborate, terror outburst refers to a society driven by constant fear and anxiety. Given this, traditional methods of addressing anxiety, such as therapy and medication, may not be accessible or appealing to everyone. This creates a significant pain point for individuals seeking immediate, non-invasive support. Our target customer segment includes young adults and professionals aged 18-35 who experience mild to moderate anxiety but may be hesitant to seek conventional treatment, where we provide an innovative alternative to support their mental wellbeing.

To ensure emotional wellbeing robots meet user needs and deliver effective support, three key pillars are essential: appearance, interactivity, and empathy. First, the robot's appearance should strike a balance between human-like and machine-like traits, fostering both comfort and trust in users \cite{decet2024}. High interactivity is also crucial; the robot should provide adaptive feedback through various stimuli to engage users effectively and enhance their emotional states \cite{wang2024}. Moreover, a robot's perceived empathic abilities play a significant role in how users interact with it, as these perceptions directly influence their willingness to attribute mental states to the robot, thereby impacting the overall quality of the interaction \cite{lillo2024}.

On the concept of emotion detection, traditional emotional detection methods utilize verbal and non-verbal cues to accurately detect and respond to human emotions. Verbal cues like pitch variations, volume \cite{hakanpaa2021}, and speech rate \cite{wang2018} are critical indicators of emotional states. For example, higher pitch and increased volume often signal heightened emotional arousal \cite{rodero2011}, as seen in both American English and Mandarin Chinese, where pitch and speed are essential for expressing emotions. Additionally, contextual understanding—interpreting emotions based on situational cues—further refines the robot's emotional recognition capabilities \cite{abbas2023}. Non-verbal cues, such as facial expressions and body language, also play a vital role. For instance, a smile usually denotes happiness \cite{chapre2023}, while crossed arms might suggest defensiveness \cite{liu2024}. By integrating these verbal and non-verbal indicators, mental wellbeing support robots can offer tailored responses, thereby improving the overall effectiveness of their interactions with users.

\subsection{Necessary Knowledge}

The development of an mental wellbeing support robot with emotional detection capabilities requires a strong foundation in various advanced concepts within artificial intelligence, machine learning, robotics, and human-computer interaction. Below is an overview of the essential knowledge areas for this project:

Machine learning models are the backbone of emotion detection systems. Convolutional Neural Networks (CNNs) \cite{taye2023} are widely used for tasks such as facial emotion recognition, where they excel at analyzing image data to identify patterns corresponding to different emotional states. In contrast, Recurrent Neural Networks (RNNs) and Long Short-Term Memory (LSTM) networks \cite{schmidt2019} are essential for processing sequential data, such as audio signals, enabling the detection of emotions through vocal features.

Effective emotion detection relies on extracting meaningful features from raw data. For instance, Mel-Frequency Cepstral Coefficients (MFCCs) \cite{singh2014} are a crucial feature extraction technique in speech emotion recognition, capturing the essential characteristics of the audio signal that correlate with emotional states. In the visual domain, key facial features like eyes, mouth, and eyebrows are extracted and analyzed by CNNs to detect emotions from facial expressions.

Natural Language Processing (NLP) is crucial for enabling the robot to understand and interpret human language, which is key to detecting emotions from text or spoken input. NLP techniques allow the robot to process language data, extracting meaningful insights such as sentiment and intent. These insights help the robot assess the emotional tone and context of the user's communication, making it possible to respond appropriately to their emotional needs \cite{khurana2017}.

The design of emotionally intelligent robots requires an understanding of Human-Robot Interaction (HRI) principles. These principles guide the development of robots that can interact naturally and empathetically with humans. Concepts such as user-friendly interface design, adaptive behavior, and empathetic response mechanisms ensure that the robot's interactions are socially acceptable and supportive \cite{bartneck2024}.

Additionally, emotionally intelligent robots rely on a combination of advanced hardware and software to accurately detect and respond to human emotions. Key hardware components, including cameras, are essential for capturing detailed facial expressions in real-time, allowing systems to effectively analyze emotional states \cite{gupta2024}. Microphones and audio sensors play a crucial role in gathering vocal cues, which are vital for emotion detection \cite{rastogi2023}. Processors and GPUs manage the heavy computational tasks, while actuators and motors control the robot's physical movements, such as gestures and facial expressions, enabling the robot to convey empathy and respond to users effectively. Haptic sensors further enhance this interaction by reacting to touch, contributing to a more interactive and supportive user experience.