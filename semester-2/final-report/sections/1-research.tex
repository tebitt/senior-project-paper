\section{Research Background}
This section will provide justifications for the project and necessary knowledge for the reader in order to
understand technical terms used throughout the report.

\subsection{Justification of the Project}

The project focuses on developing emotional well-being robots that promote mental wellness and positivity for users under the influence of stress and anxiety. In general, emotion-related robots are designed to respond to human emotions and can potentially achieve clinical outcomes similar to traditional therapy \cite{Palmer2024.07.17.24310551}. Research has shown that digital interventions, such as AI-powered mental well-being robots, can effectively reduce anxiety symptoms and address unmet mental health needs, offering a promising solution to supplement traditional therapeutic approaches \cite{jarvis2024companion}.

The mental health industry faces significant challenges that cannot be fully addressed through human intervention alone \cite{charles-2024}. Key issues include loneliness and social isolation, which are major contributors to depression, anxiety, and overall deterioration in mental health, as well as therapeutic challenges, where patients with dementia or other cognitive impairments often struggle with traditional therapeutic activities. In a study by the National Innovation Agency (NIA) based in Thailand, it was identified that the concept of \textbf{\textit{Terror Outbursts}} would become a pressing issue in Thailand by the year 2033 \cite{nia2023}. To elaborate, terror outburst refers to a society driven by constant fear and anxiety. Consequently, traditional methods of addressing anxiety, such as therapy and medication, may not be accessible or appealing to everyone. This creates a significant pain point for individuals seeking immediate, non-invasive support. Our target customer segment includes young adults and professionals aged 18-35 who experience mild to moderate anxiety but may be hesitant to seek conventional treatment, where we provide an innovative alternative to support their mental well-being.

To ensure emotional well-being robots meet user needs and deliver effective support, three key pillars are essential: appearance, interactivity, and empathy. First, the robot’s appearance should strike a balance between human-like and machine-like traits, fostering both comfort and trust in users \cite{10.1145/3640794.3665551}. High interactivity is also crucial; the robot should provide adaptive feedback through various stimuli to engage users effectively and enhance their emotional states \cite{Wang_2024}. Moreover, a robot’s perceived empathic abilities play a significant role in how users interact with it, as these perceptions directly influence their willingness to attribute mental states to the robot, thereby impacting the overall quality of the interaction \cite{lillo2024investigatingrelationshipempathyattribution}. On the concept of emotion detection, traditional emotional detection methods utilize verbal and non-verbal cues to accurately detect and respond to human emotions. Verbal cues like pitch variations, volume, and speech rate \cite{HAKANPAA2021570} are critical indicators of emotional states. For example, higher pitch and increased volume often signal heightened emotional arousal, as seen in both American English and Mandarin Chinese, where pitch and speed are essential for expressing emotions. Additionally, contextual understanding—interpreting emotions based on situational cues—further refines the robot’s emotional recognition capabilities \cite{abbas2024context}. Non-verbal cues, such as facial expressions and body language, also play a vital role. For instance, a smile usually denotes happiness, while crossed arms might suggest defensiveness \cite{liu2024emotiondetectionbodygesture}. By integrating these verbal and non-verbal indicators, mental well-being support robots can offer tailored responses, thereby improving the overall effectiveness of their interactions with users.

\subsection{Necessary Knowledge}

The development of a mental well-being support robot with emotional detection capabilities requires a strong foundation in various advanced concepts within artificial intelligence, machine learning, robotics, and human-computer interaction. Below is an overview of the essential knowledge areas for this project:

Machine learning models are the backbone of emotion detection systems. Convolutional Neural Networks (CNNs) are widely used for tasks such as facial emotion recognition, where they excel at analyzing image data to identify patterns corresponding to different emotional states. One specific architecture, VGGNet, has proven effective for emotion detection due to its deep, layered structure and ability to capture fine-grained facial features. VGGNet's simplicity in design \cite{computation11030052}, using smaller 3x3 filters stacked in depth, makes it particularly useful for recognizing subtle facial expressions that correspond to emotions. This capability enhances the accuracy of emotion detection, which is crucial for the mental well-being support robot to respond appropriately to a user's emotional state.

Another key application of machine learning used in the project is speech emotion recognition. \textbf{Speech Emotion Recognition (SER)} is an area of affective computing that aims to identify human emotions from spoken language. Emotions can be extracted by analyzing features such as \textbf{pitch, energy, spectral features,} and \textbf{prosody}, often derived from short-term frames of audio signals \cite{wu2023empiricalstudyimprovementspeech}. Traditional methods used hand-crafted features and classifiers like SVMs and HMMs, but these struggled with generalization. Deep learning approaches, especially \textbf{CNN-BiLSTM} architectures, have significantly advanced SER. \textbf{CNN-BiLSTM models} combine convolutional layers for extracting local spectral features from spectrograms with BiLSTM layers for modeling long-range temporal dependencies \cite{kundu2024enhancedspeechemotionrecognition}. This hybrid structure captures both short-term acoustic cues and long-term emotional context, improving accuracy and robustness across datasets

Next, the robot must be able to facilitate strong decision making. Bayesian Networks provide a robust framework for decision-making \cite{DBLP:journals/corr/abs-2002-00269}, enabling the robot to infer emotional states and choose appropriate responses. These graphical models represent variables and their dependencies through directed acyclic graphs (DAGs). For the robot, observable inputs like facial expressions, vocal cues, and contextual data are nodes, while hidden nodes represent inferred emotional states such as sadness or anxiety. Bayesian Networks allow the robot to integrate prior knowledge and update beliefs with new information. A belief represents the robot’s degree of confidence in a particular state or outcome, based on available evidence and prior knowledge. For example, if vocal cues indicate frustration but facial expressions appear neutral, the network can combine these inputs to infer the true emotional state. This approach assists the robot in making informed decisions and avoiding ambiguity or conflicting signals in data. 